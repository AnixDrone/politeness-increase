{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "NIk69fzP-WrI"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/tignjatov/anaconda3/envs/ml/lib/python3.6/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import torch \n",
        "import pandas as pd\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import tqdm\n",
        "import sys\n",
        "sys.path.append('./data_prep')\n",
        "from sentence_dataset_class import ProcessedSentences\n",
        "from sentence_processing import build_vocab,sentence_processing\n",
        "sys.path.append('./transformer_testing')\n",
        "from tomislav_transformer import Seq2SeqTransformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "hER3sVP--WrP"
      },
      "outputs": [],
      "source": [
        "def stringify_series(df):\n",
        "    df['input_data'] = df['input_data'].astype('string')\n",
        "    df['output_data'] = df['output_data'].astype('string')\n",
        "    return df\n",
        "\n",
        "def generate_square_subsequent_mask(sz):\n",
        "    mask = (torch.triu(torch.ones((sz, sz), device=device)) == 1).transpose(0, 1)\n",
        "    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
        "    return mask\n",
        "\n",
        "def create_mask(src, tgt):\n",
        "    src_seq_len = src.shape[0]\n",
        "    tgt_seq_len = tgt.shape[0]\n",
        "\n",
        "    tgt_mask = generate_square_subsequent_mask(tgt_seq_len)\n",
        "    src_mask = torch.zeros((src_seq_len, src_seq_len),device=device).type(torch.bool)\n",
        "\n",
        "    src_padding_mask = (src == PAD_IDX).transpose(0, 1)\n",
        "    tgt_padding_mask = (tgt == PAD_IDX).transpose(0, 1)\n",
        "    return src_mask, tgt_mask, src_padding_mask, tgt_padding_mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "BaEqFx1b-WrQ"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "P6YdBJo4-WrR"
      },
      "outputs": [],
      "source": [
        "df_train = pd.read_json('data/train_data.json')\n",
        "df_test = pd.read_json('data/test_data.json')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "wEMgbOaj-WrS"
      },
      "outputs": [],
      "source": [
        "token_transform = get_tokenizer('basic_english')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "_6IptDuu-WrS"
      },
      "outputs": [],
      "source": [
        "UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
        "special_symbols = ['<unk>', '<pad>', '<bos>', '<eos>']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "EKW2s6kM-WrT"
      },
      "outputs": [],
      "source": [
        "train_input_vocab = build_vocab(df_train['input_data'],token_transform,special_symbols)\n",
        "train_output_vocab = build_vocab(df_train['output_data'],token_transform,special_symbols)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "7E6L0oL4-WrY"
      },
      "outputs": [],
      "source": [
        "train_dataset = ProcessedSentences(\n",
        "    input_data = df_train['input_data'].values,\n",
        "    output_data = df_train['output_data'].values,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "dHXcUF6A-WrY"
      },
      "outputs": [],
      "source": [
        "test_dataset = ProcessedSentences(\n",
        "    input_data = df_test['input_data'].values,\n",
        "    output_data = df_test['output_data'].values\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "uZesaF3Z3Dc7"
      },
      "outputs": [],
      "source": [
        "def collate_fn(batch):\n",
        "    input_tensor = []\n",
        "    output_tensor = []\n",
        "    for input,output in batch:\n",
        "        input_tensor.append(sentence_processing(input,\n",
        "                                             train_input_vocab,\n",
        "                                             token_transform,\n",
        "                                             special_symbols.index('<bos>'),special_symbols.index('<eos>')\n",
        "                                             )\n",
        "                            )\n",
        "        output_tensor.append(sentence_processing(output,\n",
        "                                             train_output_vocab,\n",
        "                                             token_transform,\n",
        "                                             special_symbols.index('<bos>'),special_symbols.index('<eos>')\n",
        "                                             ))\n",
        "    src_batch = pad_sequence(input_tensor, padding_value=PAD_IDX)\n",
        "    tgt_batch = pad_sequence(output_tensor, padding_value=PAD_IDX)\n",
        "    return src_batch, tgt_batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "3WJNk-9l-WrZ"
      },
      "outputs": [],
      "source": [
        "train_dataloader = DataLoader(train_dataset,batch_size=32,shuffle=True,collate_fn=collate_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "for input,output in train_dataloader:\n",
        "    out = output[:-1,:]\n",
        "    x = out[:,1]\n",
        "   \n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "real_sent = list(x.numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"<bos> if i can get out of here at a decent time i ' ll finish it tonight . <eos> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\""
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "' '.join(train_output_vocab.lookup_tokens(real_sent))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eQ7dVNIl-WrZ"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(0)\n",
        "input_vocab_size = len(train_input_vocab)\n",
        "output_vocab_size = len(train_output_vocab)\n",
        "emb_size = 256\n",
        "n_head = 2\n",
        "ffn_hid_dim = 512\n",
        "batch_size = 128\n",
        "num_encoder_layers = 1\n",
        "num_decoder_layers = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DDS_PwX6-Wra"
      },
      "outputs": [],
      "source": [
        "transformer = Seq2SeqTransformer(\n",
        "    num_encoder_layers,\n",
        "    num_decoder_layers,\n",
        "    emb_size,\n",
        "    n_head,\n",
        "    input_vocab_size,\n",
        "    output_vocab_size,\n",
        "    ffn_hid_dim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-yBAP2T1-Wra"
      },
      "outputs": [],
      "source": [
        "transformer = transformer.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "41xPFnMY-Wrb"
      },
      "outputs": [],
      "source": [
        "loss_fn = torch.nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
        "optimizer = torch.optim.Adam(transformer.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ANS4hlGc-Wrb"
      },
      "outputs": [],
      "source": [
        "def train_epoch(model,optimizer):\n",
        "    model.train()\n",
        "    losses = 0\n",
        "    train_dataloader = DataLoader(train_dataset,batch_size=batch_size,shuffle=True,collate_fn=collate_fn)\n",
        "    for input_sent, output_sent in tqdm.tqdm(train_dataloader):\n",
        "        input_sent = input_sent.to(device)\n",
        "        output_sent = output_sent.to(device)\n",
        "        \n",
        "        output_input = output_sent[:-1,:]\n",
        "        \n",
        "        input_mask, output_mask, input_padding_mask, output_padding_mask = create_mask(input_sent,output_input)\n",
        "        logits = model(\n",
        "            input_sent,\n",
        "            output_input,\n",
        "            input_mask,\n",
        "            output_mask,\n",
        "            input_padding_mask,\n",
        "            output_padding_mask,\n",
        "            input_padding_mask)\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        output_out = output_sent[1:,:]\n",
        "        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), output_out.reshape(-1))\n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "        losses += loss.item()\n",
        "    return losses/len(train_dataloader)\n",
        "def evaluate(model):\n",
        "    model.eval()\n",
        "    losses = 0\n",
        "    test_dataloader = DataLoader(test_dataset,batch_size=batch_size,shuffle=True,collate_fn=collate_fn)\n",
        "    for input_sent, output_sent in tqdm.tqdm(test_dataloader):\n",
        "        input_sent = input_sent.to(device)\n",
        "        output_sent = output_sent.to(device)\n",
        "        \n",
        "        output_input = output_sent[:-1,:]\n",
        "        input_mask, output_mask, input_padding_mask, output_padding_mask = create_mask(input_sent,output_input)\n",
        "        logits = model(\n",
        "            input_sent,\n",
        "            output_input,\n",
        "            input_mask,\n",
        "            output_mask,\n",
        "            input_padding_mask,\n",
        "            output_padding_mask,\n",
        "            input_padding_mask)\n",
        "        \n",
        "        \n",
        "        output_out = output_sent[1:,:]\n",
        "        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), output_out.reshape(-1))\n",
        "        \n",
        "        losses += loss.item()\n",
        "    return losses/len(test_dataloader)\n",
        "    \n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40gJVl24-Wrc",
        "outputId": "3277fb91-59de-40ed-8a61-7093a8a11136"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1661/1661 [03:03<00:00,  9.04it/s]\n",
            "100%|██████████| 202/202 [00:09<00:00, 22.22it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1, Train loss: 5.485, Val loss: 4.843\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1661/1661 [03:00<00:00,  9.20it/s]\n",
            "100%|██████████| 202/202 [00:09<00:00, 21.96it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 2, Train loss: 4.742, Val loss: 4.477\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import tqdm\n",
        "num_epochs = 2\n",
        "\n",
        "for epoch in range(1,num_epochs+1):\n",
        "    train_loss = train_epoch(transformer,optimizer)\n",
        "    val_loss = evaluate(transformer)\n",
        "    print(f\"Epoch: {epoch}, Train loss: {train_loss:.3f}, Val loss: {val_loss:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0lz5gNil-Wrd"
      },
      "outputs": [],
      "source": [
        "def greedy_decode(model, src, src_mask, max_len, start_symbol):\n",
        "    src = src.to(device)\n",
        "    src_mask = src_mask.to(device)\n",
        "\n",
        "    memory = model.encode(src, src_mask)\n",
        "    ys = torch.ones(1, 1).fill_(start_symbol).type(torch.long).to(device)\n",
        "    for i in range(max_len-1):\n",
        "        memory = memory.to(device)\n",
        "        tgt_mask = (generate_square_subsequent_mask(ys.size(0))\n",
        "                    .type(torch.bool)).to(device)\n",
        "        out = model.decode(ys, memory, tgt_mask)\n",
        "        out = out.transpose(0, 1)\n",
        "        prob = model.generator(out[:, -1])\n",
        "        _, next_word = torch.max(prob, dim=1)\n",
        "        next_word = next_word.item()\n",
        "\n",
        "        ys = torch.cat([ys,\n",
        "                        torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=0)\n",
        "        if next_word == EOS_IDX:\n",
        "            break\n",
        "    return ys\n",
        "  # actual function to translate input sentence into target language\n",
        "def translate(model: torch.nn.Module, input_sentence: str):\n",
        "    model.eval()\n",
        "    src = sentence_processing(input_sentence,\n",
        "                              train_input_vocab,\n",
        "                              token_transform,\n",
        "                              BOS_IDX,\n",
        "                              EOS_IDX).view(-1, 1)\n",
        "    num_tokens = src.shape[0]\n",
        "    src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool)\n",
        "    tgt_tokens = greedy_decode(\n",
        "        model,  src, src_mask, max_len=num_tokens + 5, start_symbol=BOS_IDX).flatten()\n",
        "    return \" \".join(train_output_vocab.lookup_tokens(list(tgt_tokens.cpu().numpy()))).replace(\"<bos>\", \"\").replace(\"<eos>\", \"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zthghIBZBsSa",
        "outputId": "843e1a76-846b-4c4a-fd46-005bae9d7ca6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " <unk> , and new york and new york and new york and new\n"
          ]
        }
      ],
      "source": [
        "print(translate(transformer,\"good drinks , and good company .\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "saKBH4ULB1S2"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "main_training.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.6.13 ('ml')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.13"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "e52387336156db6d881f08b29d2996eae333b560bff7fc97cb6248ede68f9d47"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
