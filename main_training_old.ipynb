{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tignjatov/anaconda3/envs/ml/lib/python3.6/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import pandas as pd\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import sys\n",
    "sys.path.append('./data_prep')\n",
    "from sentence_dataset_class import ProcessedSentences\n",
    "from sentence_processing import build_vocab,sentence_processing\n",
    "sys.path.append('./transformer_testing')\n",
    "from tomislav_transformer import Seq2SeqTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stringify_series(df):\n",
    "    df['input_data'] = df['input_data'].astype('string')\n",
    "    df['output_data'] = df['output_data'].astype('string')\n",
    "    return df\n",
    "\n",
    "def generate_square_subsequent_mask(sz):\n",
    "    mask = (torch.triu(torch.ones((sz, sz), device=device)) == 1).transpose(0, 1)\n",
    "    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "    return mask\n",
    "\n",
    "def create_mask(src, tgt):\n",
    "    src_seq_len = src.shape[0]\n",
    "    tgt_seq_len = tgt.shape[0]\n",
    "\n",
    "    tgt_mask = generate_square_subsequent_mask(tgt_seq_len)\n",
    "    src_mask = torch.zeros((src_seq_len, src_seq_len),device=device).type(torch.bool)\n",
    "\n",
    "    src_padding_mask = (src == PAD_IDX).transpose(0, 1)\n",
    "    tgt_padding_mask = (tgt == PAD_IDX).transpose(0, 1)\n",
    "    return src_mask, tgt_mask, src_padding_mask, tgt_padding_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_json('data/train_data.json')\n",
    "df_test = pd.read_json('data/test_data.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_transform = get_tokenizer('basic_english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
    "special_symbols = ['<unk>', '<pad>', '<bos>', '<eos>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_vocab = build_vocab(df_train['input_data'],token_transform,special_symbols)\n",
    "train_output_vocab = build_vocab(df_train['output_data'],token_transform,special_symbols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_input_sentences = [sentence_processing(sentence,\n",
    "#                                              train_input_vocab,\n",
    "#                                              token_transform,\n",
    "#                                              special_symbols.index('<bos>'),special_symbols.index('<eos>'))\n",
    "#                          for sentence in df_train['input_data'].values]\n",
    "# train_output_sentences = [sentence_processing(sentence,\n",
    "#                                               train_output_vocab,\n",
    "#                                               token_transform,\n",
    "#                                               special_symbols.index('<bos>'),\n",
    "#                                               special_symbols.index('<eos>'))\n",
    "#                           for sentence in df_train['output_data'].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_input_sentences = [sentence_processing(sentence,train_input_vocab,token_transform,special_symbols.index('<bos>'),special_symbols.index('<eos>')) for sentence in df_test['input_data'].values]\n",
    "# test_output_sentences = [sentence_processing(sentence,train_output_vocab,token_transform,special_symbols.index('<bos>'),special_symbols.index('<eos>')) for sentence in df_test['output_data'].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # train_input_sentences = pad_sequence(train_input_sentences,batch_first=True,padding_value=PAD_IDX)\n",
    "# # train_output_sentences = pad_sequence(train_output_sentences,batch_first=True,padding_value=PAD_IDX)\n",
    "# # test_input_sentences = pad_sequence(test_input_sentences,batch_first=True,padding_value=PAD_IDX)\n",
    "# # test_output_sentences = pad_sequence(test_output_sentences,batch_first=True,padding_value=PAD_IDX)\n",
    "\n",
    "# train_input_sentences_padded = pad_sequence(train_input_sentences,padding_value=PAD_IDX)\n",
    "# train_output_sentences_padded = pad_sequence(train_output_sentences,padding_value=PAD_IDX)\n",
    "# test_input_sentences_padded = pad_sequence(test_input_sentences,padding_value=PAD_IDX)\n",
    "# test_output_sentences_padded = pad_sequence(test_output_sentences,padding_value=PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ProcessedSentences(\n",
    "    input_data = df_train['input_data'].values,\n",
    "    output_data = df_train['output_data'].values,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = ProcessedSentences(\n",
    "    input_data = df_test['input_data'].values,\n",
    "    output_data = df_test['output_data'].values\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    input_tensor = []\n",
    "    output_tensor = []\n",
    "    for input,output in batch:\n",
    "        input_tensor.append(sentence_processing(input,\n",
    "                                             train_input_vocab,\n",
    "                                             token_transform,\n",
    "                                             special_symbols.index('<bos>'),special_symbols.index('<eos>')\n",
    "                                             )\n",
    "                            )\n",
    "        output_tensor.append(sentence_processing(output,\n",
    "                                             train_output_vocab,\n",
    "                                             token_transform,\n",
    "                                             special_symbols.index('<bos>'),special_symbols.index('<eos>')\n",
    "                                             ))\n",
    "    src_batch = pad_sequence(input_tensor, padding_value=PAD_IDX)\n",
    "    tgt_batch = pad_sequence(output_tensor, padding_value=PAD_IDX)\n",
    "    return src_batch, tgt_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset,batch_size=128,shuffle=True,collate_fn=collate_fn)\n",
    "#test_dataloader = DataLoader(test_dataset,batch_size=32,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1661"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "input_vocab_size = len(train_input_vocab)\n",
    "output_vocab_size = len(train_output_vocab)\n",
    "emb_size = 512\n",
    "n_head = 8\n",
    "ffn_hid_dim = 512\n",
    "batch_size = 128\n",
    "num_encoder_layers = 3\n",
    "num_decoder_layers = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = Seq2SeqTransformer(\n",
    "    num_encoder_layers,\n",
    "    num_decoder_layers,\n",
    "    emb_size,\n",
    "    n_head,\n",
    "    input_vocab_size,\n",
    "    output_vocab_size,\n",
    "    ffn_hid_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = transformer.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
    "optimizer = torch.optim.Adam(transformer.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model,optimizer):\n",
    "    model.train()\n",
    "    losses = 0\n",
    "    train_dataloader = DataLoader(train_dataset,batch_size=batch_size,shuffle=True,collate_fn=collate_fn)\n",
    "    for input_sent, output_sent in train_dataloader:\n",
    "        input_sent = input_sent.to(device)\n",
    "        output_sent = output_sent.to(device)\n",
    "        \n",
    "        output_input = output_sent[:-1,:]\n",
    "        \n",
    "        input_mask, output_mask, input_padding_mask, output_padding_mask = create_mask(input_sent,output_input)\n",
    "        logits = model(\n",
    "            input_sent,\n",
    "            output_input,\n",
    "            input_mask,\n",
    "            output_mask,\n",
    "            input_padding_mask,\n",
    "            output_padding_mask,\n",
    "            input_padding_mask)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output_out = output_sent[1:,:]\n",
    "        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), output_out.reshape(-1))\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        losses += loss.item()\n",
    "    return losses/len(train_dataloader)\n",
    "def evaluate(model):\n",
    "    model.eval()\n",
    "    losses = 0\n",
    "    test_dataloader = DataLoader(test_dataset,batch_size=batch_size,shuffle=True,collate_fn=collate_fn)\n",
    "    for input_sent, output_sent in test_dataloader:\n",
    "        input_sent = input_sent.to(device)\n",
    "        output_sent = output_sent.to(device)\n",
    "        \n",
    "        output_input = output_sent[:-1,:]\n",
    "        input_mask, output_mask, input_padding_mask, output_padding_mask = create_mask(input_sent,output_input)\n",
    "        logits = model(\n",
    "            input_sent,\n",
    "            output_input,\n",
    "            input_mask,\n",
    "            output_mask,\n",
    "            input_padding_mask,\n",
    "            output_padding_mask,\n",
    "            input_padding_mask)\n",
    "        \n",
    "        \n",
    "        output_out = output_sent[1:,:]\n",
    "        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), output_out.reshape(-1))\n",
    "        \n",
    "        losses += loss.item()\n",
    "    return losses/len(test_dataloader)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([54, 32])\n",
      "tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
      "        [  22,    5,    5,  ..., 2407,   91, 1191],\n",
      "        [   8,  131,    0,  ...,    6,  571,   14],\n",
      "        ...,\n",
      "        [   1,    1,    1,  ...,    1,    1,    1],\n",
      "        [   1,    1,    1,  ...,    1,    1,    1],\n",
      "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n",
      "torch.Size([68, 32])\n",
      "tensor([[    2,     2,     2,  ...,     2,     2,     2],\n",
      "        [  192,  2983,     8,  ..., 10198,     9,     0],\n",
      "        [   17,     7,     5,  ...,  2979,    41,    32],\n",
      "        ...,\n",
      "        [    1,     1,     1,  ...,     1,     1,     1],\n",
      "        [    1,     1,     1,  ...,     1,     1,     1],\n",
      "        [    1,     1,     1,  ...,     1,     1,     1]], device='cuda:0')\n",
      "torch.Size([30, 32])\n",
      "tensor([[    2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
      "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
      "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
      "             2,     2],\n",
      "        [   66,   322,     9,    24,     6,    29,     9,    66,  1146,     9,\n",
      "          1292,    18,    49,     9,    10,     7,    21,  3748,  2244,   463,\n",
      "             9,  2849,    76,     9,    17,   625,     9,     9,    39,    26,\n",
      "             6,   207],\n",
      "        [   13,     0, 10178,    20,  1959,    18,    61,     9,     7,    18,\n",
      "             6,     7,     7,    37,   114,   560,     5,     6,     6,     6,\n",
      "            18,     6, 10004,   220,  1546,    20,    13,    13,   118,    14,\n",
      "         11361,     7],\n",
      "        [   25,    41,    86,   122,    96,  3368,    40,  1416,   633,  1161,\n",
      "            50,    63,   269,    79,  4964,    34,  1048,   715,     9,    46,\n",
      "             8,     9,  1298,    34,    43,    80,    60,    60,     6,   472,\n",
      "             5,   519],\n",
      "        [ 1044,   512,    58,     7,    84,   441,     7,     7,    34,    11,\n",
      "             4,    51,     8,    37,     6,   840,  1566,  2468,   305, 13395,\n",
      "            11,     7,    10,  2150,  4531,   314,     8,    30,   159,     6,\n",
      "          1455,    46],\n",
      "        [    7,    17,     5,    99,    48,     6,   140,   519,     0,     4,\n",
      "             3,    29,   896,   171,     5,     6,  8558,    17,     7,  5341,\n",
      "          1152,  2496,    49,   517,     4,     7,   118,     4,     8,     5,\n",
      "             7,   225],\n",
      "        [   18,     5,   229,   187,     9,  2455,     8,    70,  6387,     3,\n",
      "             1,    46,  1702,     5,   576,     5,     6,    78,   280,    14,\n",
      "             9,    18,     5,     8,     3,     5,     4,     3,   203,     0,\n",
      "            55,     6],\n",
      "        [   10,  6654,     6,    21,     8,     6,  3900,     8,    17,     1,\n",
      "             1,  2336,     5,   688, 13661,   174,  2640,     4,     7,   701,\n",
      "           143,    15,   184,  2217,     1, 17756,     3,     1,    16,    20,\n",
      "             3,    36],\n",
      "        [    4,     4,    51,     5,  1432,    10,     7,   347,    44,     1,\n",
      "             1,   111,   292,    10,     8,    27,     8,     3,     0,   805,\n",
      "             4,   265,    11,    14,     1,     7,     1,     1,    47,   113,\n",
      "             1,     9],\n",
      "        [    3,     3,    10,   859,    17,  1049,   525,   267,    44,     1,\n",
      "             1,    16,  1083,   252,   503, 11594,   859,     1,   285,    16,\n",
      "             3,     7,    12,   133,     1, 10739,     1,     1,    11,  5634,\n",
      "             1,    23],\n",
      "        [    1,     1,  1199,    11,     5,  1233,   323,    11,    44,     1,\n",
      "             1,     8,   788,     4,   100,     4,  1533,     1,    10,  1050,\n",
      "             1,     8,    19,  9427,     1,    64,     1,     1,     5,     6,\n",
      "             1,    40],\n",
      "        [    1,     1,    11,  1692,   141,    55,    26, 15644,    44,     1,\n",
      "             1,   909,   200,     3,    58,   163,   539,     1,    62,    27,\n",
      "             1,  1154,    82,    44,     1,   417,     1,     1,  4003,    36,\n",
      "             1,   195],\n",
      "        [    1,     1,     4,    22,     4,     3,   468,   167,    44,     1,\n",
      "             1,    33,    11,     1,    63,    38,    14,     1,   686, 11190,\n",
      "             1,  1823,  4700,     3,     1,  1440,     1,     1,   130,    12,\n",
      "             1,   401],\n",
      "        [    1,     1,     3,    29,     3,     1,    62,   601,     3,     1,\n",
      "             1,     8,     5,     1,   349, 10845,     5,     1,    11,    61,\n",
      "             1,     9,     4,     1,     1,    10,     1,     1,     4,     5,\n",
      "             1,    47],\n",
      "        [    1,     1,     1,   123,     1,     1,    11,   518,     1,     1,\n",
      "             1, 18578,  1643,     1,    11,     5,  2557,     1,    75,    14,\n",
      "             1,    79,     3,     1,     1,    11,     1,     1,     3,  7386,\n",
      "             1,     4],\n",
      "        [    1,     1,     1,   303,     1,     1,   108,     4,     1,     1,\n",
      "             1,   129,    15,     1,     5, 11594,    11,     1,   779,   754,\n",
      "             1,    40,     1,     1,     1,     8,     1,     1,     1,    11,\n",
      "             1,     3],\n",
      "        [    1,     1,     1,     4,     1,     1,   532,     3,     1,     1,\n",
      "             1,   292,    74,     1,    89,  1281,     4,     1,    21,   598,\n",
      "             1,   905,     1,     1,     1,     0,     1,     1,     1,    49,\n",
      "             1,     1],\n",
      "        [    1,     1,     1,     3,     1,     1,  1852,     1,     1,     1,\n",
      "             1,     4,  3322,     1,     4,  1576,     3,     1,  1323,     8,\n",
      "             1,    27,     1,     1,     1,  2497,     1,     1,     1,  1009,\n",
      "             1,     1],\n",
      "        [    1,     1,     1,     1,     1,     1,     4,     1,     1,     1,\n",
      "             1,     3,     4,     1,     3,  1630,     1,     1,     7,   455,\n",
      "             1,    19,     1,     1,     1,  3375,     1,     1,     1,    12,\n",
      "             1,     1],\n",
      "        [    1,     1,     1,     1,     1,     1,     3,     1,     1,     1,\n",
      "             1,     1,     3,     1,     1,    93,     1,     1,     5,     7,\n",
      "             1,   196,     1,     1,     1,  1516,     1,     1,     1,     0,\n",
      "             1,     1],\n",
      "        [    1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,   108,     1,     1,  6998,     5,\n",
      "             1,     4,     1,     1,     1,   168,     1,     1,     1,     4,\n",
      "             1,     1],\n",
      "        [    1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1, 13575,     1,     1,    11, 11190,\n",
      "             1,     3,     1,     1,     1,     4,     1,     1,     1,     3,\n",
      "             1,     1],\n",
      "        [    1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,   150,     1,     1,     5,     6,\n",
      "             1,     1,     1,     1,     1,     3,     1,     1,     1,     1,\n",
      "             1,     1],\n",
      "        [    1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     4,     1,     1,  5252,    36,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1],\n",
      "        [    1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     3,     1,     1,     4,    40,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1],\n",
      "        [    1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     3,     7,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1],\n",
      "        [    1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,  1102,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1],\n",
      "        [    1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,    81,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1],\n",
      "        [    1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     4,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1],\n",
      "        [    1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     3,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1]], device='cuda:0')\n",
      "torch.Size([44, 32])\n",
      "tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
      "        [  7,   9, 251,  ...,   9,   5,  35],\n",
      "        [916,  19, 161,  ..., 973, 286,  49],\n",
      "        ...,\n",
      "        [  1,   1,   1,  ...,   1,   1,   1],\n",
      "        [  1,   1,   1,  ...,   1,   1,   1],\n",
      "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
      "torch.Size([79, 32])\n",
      "tensor([[    2,     2,     2,  ...,     2,     2,     2],\n",
      "        [12583,     9,   222,  ...,     9,     9,   400],\n",
      "        [   72,    18,    11,  ...,     7,    17,     5],\n",
      "        ...,\n",
      "        [    1,     1,     1,  ...,     1,     1,     1],\n",
      "        [    1,     1,     1,  ...,     1,     1,     1],\n",
      "        [    1,     1,     1,  ...,     1,     1,     1]], device='cuda:0')\n",
      "torch.Size([41, 32])\n",
      "tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
      "        [ 80,   9,  32,  ...,  26,   9,  10],\n",
      "        [  6,  62, 132,  ...,  22, 254,   9],\n",
      "        ...,\n",
      "        [  1,   1,   1,  ...,   1,   1,   1],\n",
      "        [  1,   1,   1,  ...,   1,   1,   1],\n",
      "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
      "torch.Size([66, 32])\n",
      "tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
      "        [  6,   9,   6,  ...,   9,  28, 205],\n",
      "        [ 10,   7,   5,  ...,  42,  18,   6],\n",
      "        ...,\n",
      "        [  1,   1,   1,  ...,   1,   1,   1],\n",
      "        [  1,   1,   1,  ...,   1,   1,   1],\n",
      "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n",
      "torch.Size([113, 32])\n",
      "tensor([[    2,     2,     2,  ...,     2,     2,     2],\n",
      "        [   24,    22,    12,  ...,   119,  1216,     9],\n",
      "        [ 1412,     8,  1186,  ...,   526, 12591,   511],\n",
      "        ...,\n",
      "        [    1,     1,     1,  ...,     1,     1,     1],\n",
      "        [    1,     1,     1,  ...,     1,     1,     1],\n",
      "        [    1,     1,     1,  ...,     1,     1,     1]], device='cuda:0')\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 300.00 MiB (GPU 0; 3.94 GiB total capacity; 1.89 GiB already allocated; 225.38 MiB free; 2.17 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-2f75b2cddd73>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch: {epoch}, Train loss: {train_loss:.3f}, Val loss: {val_loss:.3f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-61c61df03bc7>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(model, optimizer)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0moutput_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_sent\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml/lib/python3.6/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    154\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 300.00 MiB (GPU 0; 3.94 GiB total capacity; 1.89 GiB already allocated; 225.38 MiB free; 2.17 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(1,num_epochs+1):\n",
    "    train_loss = train_epoch(transformer,optimizer)\n",
    "    val_loss = evaluate(transformer)\n",
    "    print(f\"Epoch: {epoch}, Train loss: {train_loss:.3f}, Val loss: {val_loss:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "hyper_params = {}\n",
    "with open('hyperparameters.json', 'r') as f:\n",
    "    hyper_params = json.load(f)\n",
    "\n",
    "with open('test.json', 'w' ) as f :\n",
    "    json.dump(hyper_params, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'emb_size': 256,\n",
       " 'n_head': 2,\n",
       " 'ffn_hid_dim': 512,\n",
       " 'batch_size': 128,\n",
       " 'num_encoder_layers': 1,\n",
       " 'num_decoder_layers': 1,\n",
       " 'epochs': 2}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyper_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'05_08-2022_01_32_20.json'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time.strftime(\"%d_%m-%Y_%H_%M_%S\", time.localtime())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data.metrics import bleu_score\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "len() of a 0-d tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-7e643463d39c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbleu_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/ml/lib/python3.6/site-packages/torchtext/data/metrics.py\u001b[0m in \u001b[0;36mbleu_score\u001b[0;34m(candidate_corpus, references_corpus, max_n, weights)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcandidate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrefs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_corpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreferences_corpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0mcandidate_len\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;31m# Get the length of the reference that's closest in length to the candidate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml/lib/python3.6/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36m__len__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    622\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__len__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    623\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 624\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"len() of a 0-d tensor\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    625\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m             warnings.warn('Using len to get tensor shape might cause the trace to be incorrect. '\n",
      "\u001b[0;31mTypeError\u001b[0m: len() of a 0-d tensor"
     ]
    }
   ],
   "source": [
    "bleu_score(torch.tensor([1,1,1,1,1,1]),torch.tensor([1,1,1,1,1,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8408964276313782"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchtext.data.metrics import bleu_score\n",
    "candidate_corpus = [['My', 'full', 'pytorch', 'test'], ['Another', 'Sentence']]\n",
    "references_corpus = [[['My', 'full', 'pytorch', 'test'], ['Completely', 'Different']], [['No', 'Match']]]\n",
    "bleu_score(candidate_corpus, references_corpus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data.utils import get_tokenizer\n",
    "tok = get_tokenizer(\"basic_english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_sentences = ['Give me the documents',\n",
    "                     'Return the files right away',\n",
    "                     'I need the documents',\n",
    "                     'I want to return the files',\n",
    "                     'I want to return the files right away',\n",
    "                     'Answer the phone right away',\n",
    "                     ]\n",
    "my_sentences = ['Please give me the documents',\n",
    "                'Please return the files right away',\n",
    "                'Please answer the phone right away',\n",
    "                'Please return the files',\n",
    "                'Answer the phone right away',\n",
    "                'Wake up']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "The length of candidate and reference corpus should be the same",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-39848ab99206>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtok_ex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtok\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexample_sentences\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtok_my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtok\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmy_sentences\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mbleu_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtok_my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtok_ex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtok_ex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/ml/lib/python3.6/site-packages/torchtext/data/metrics.py\u001b[0m in \u001b[0;36mbleu_score\u001b[0;34m(candidate_corpus, references_corpus, max_n, weights)\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mmax_n\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Length of the \"weights\" list has be equal to max_n'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_corpus\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreferences_corpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0;34m'The length of candidate and reference corpus should be the same'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0mclipped_counts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_n\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: The length of candidate and reference corpus should be the same"
     ]
    }
   ],
   "source": [
    "tok_ex = [tok(s )for s in example_sentences]\n",
    "tok_my = [tok(s) for s in my_sentences]\n",
    "bleu_score(tok_my,[tok_ex,tok_ex])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.13 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e52387336156db6d881f08b29d2996eae333b560bff7fc97cb6248ede68f9d47"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
